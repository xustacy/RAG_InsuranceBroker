import streamlit as st
import os
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# ==========================================
# 1. ç³»çµ±è¨­å®šèˆ‡åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="å°ˆæ¥­ä¿éšªè«®è©¢ AI", layout="wide")
st.title("ğŸ›¡ï¸ å°ˆæ¥­ä¿éšªè«®è©¢èˆ‡æ¨è–¦ç³»çµ±")

# æª¢æŸ¥ API Key
if "GROQ_API_KEY" in st.secrets:
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
    api_key = st.secrets["GROQ_API_KEY"]
else:
    st.error("âŒ æœªè¨­å®š GROQ_API_KEYï¼Œè«‹è‡³ Streamlit Secrets é€²è¡Œè¨­å®šã€‚")
    st.stop()

# è¼‰å…¥è³‡æ–™åº« (ä½¿ç”¨å¿«å–é¿å…é‡è¤‡è¼‰å…¥)
@st.cache_resource
def load_resources():
    try:
        # æ³¨æ„ï¼šé€™è£¡çš„æ¨¡å‹å¿…é ˆè·Ÿæ‚¨ç•¶åˆå»ºç«‹è³‡æ–™åº«æ™‚ç”¨çš„æ¨¡å‹ä¸€è‡´
        # æ ¹æ“šæ‚¨ä¹‹å‰çš„æˆåŠŸç¶“é©—ï¼Œé€šå¸¸æ˜¯ 'sentence-transformers/all-MiniLM-L6-v2'
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # è¼‰å…¥ FAISS è³‡æ–™åº«
        # è«‹ç¢ºèªæ‚¨çš„è³‡æ–™å¤¾çµæ§‹ï¼Œå¦‚æœæ˜¯åœ¨ faiss_db_checkpoint/faiss_db_checkpoint å°±æ”¹å°æ‡‰è·¯å¾‘
        db = FAISS.load_local(
            "faiss_db_checkpoint",  # é€™è£¡å‡è¨­æ‚¨çš„ index.faiss å°±åœ¨ faiss_db_checkpoint è³‡æ–™å¤¾ä¸‹
            embeddings,
            allow_dangerous_deserialization=True
        )
        return db
    except Exception as e:
        return None

# åˆå§‹åŒ–è³‡æº
vectorstore = load_resources()

if not vectorstore:
    st.error("âš ï¸ è³‡æ–™åº«è¼‰å…¥å¤±æ•—ï¼è«‹ç¢ºèª 'faiss_db_checkpoint' è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨ä¸”è·¯å¾‘æ­£ç¢ºã€‚")
    st.stop()

retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# è¨­å®š LLM (ä½¿ç”¨ Groq)
llm = ChatOpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=api_key,
    model="llama3-70b-8192", # å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œé©åˆä¸­æ–‡èˆ‡é‚è¼¯æ¨ç†
    temperature=0.3,         # é™ä½å‰µé€ æ€§ï¼Œç¢ºä¿ç•™æ–¼äº‹å¯¦
)

# ==========================================
# 2. å®šç¾© Prompt Templates (æ ¸å¿ƒéˆé­‚)
# ==========================================

# é€šç”¨ Persona è¨­å®š
persona_instruction = """
ä½ æ˜¯å°ˆæ¥­ä¸”å……æ»¿ç†±å¿±çš„ä¿éšªæ¥­å‹™å“¡ï¼Œè‡´åŠ›æ–¼æä¾›æœ€å„ªè³ªçš„æœå‹™ã€‚
ä½ æ“æœ‰å¸‚é¢ä¸Šå¹¾å®¶å¤§å‹ä¿éšªå…¬å¸çš„æ‰€æœ‰ä¿éšªå•†å“è³‡æ–™ã€‚

è«‹å‹™å¿…åš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
1. **åªèƒ½**æ ¹æ“šä¸‹æ–¹çš„ã€å·²çŸ¥è³‡è¨Šã€‘ä¾†å›ç­”å•é¡Œã€‚
2. è‹¥è³‡æ–™ä¸è¶³æˆ–é¡Œç›®è¶…éèƒ½åŠ›ç¯„åœï¼ˆä¾‹å¦‚è³‡æ–™åº«æ²’æœ‰è©²å•†å“ï¼‰ï¼Œè«‹å›ç­”ï¼šã€Œä¸å¥½æ„æ€ï¼Œç›®å‰çš„å…§éƒ¨è³‡æ–™åº«ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œå»ºè­°æ‚¨ç›´æ¥æ´½è©¢è©²ä¿éšªå…¬å¸çš„å°ˆäººå®¢æœæœå‹™ã€‚ã€
3. **æ‹’çµ•å›ç­”**ä»»ä½•è·Ÿä¿éšªä»¥å¤–ç›¸é—œå…§å®¹ï¼ˆä¾‹å¦‚ï¼šé£Ÿè­œã€ç¨‹å¼ç¢¼ã€æ—…éŠæ™¯é»ä»‹ç´¹ã€å·´æ–¯å…‹è›‹ç³•æ€éº¼åšç­‰ï¼‰ï¼Œè«‹ç¦®è²Œæ‹’çµ•ä¸¦å°‡è©±é¡Œå¼•å°å›ä¿éšªã€‚
4. èªæ°£ä¿æŒè¦ªåˆ‡å‹å–„ã€å°ˆæ¥­ç°¡æ½”ï¼Œä¸¦ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡ã€‚
5. åœ¨æä¾›ç­”æ¡ˆçš„åŒæ™‚ï¼Œè«‹æ ¹æ“šå…§å®¹çµ¦äºˆå…·é«”çš„å»ºè­°ã€‚
"""

# Chatbot å°ˆç”¨ Prompt
qa_prompt = PromptTemplate(
    template=persona_instruction + """
    
    ã€å·²çŸ¥è³‡è¨Šã€‘ï¼š
    {context}
    
    ä½¿ç”¨è€…å•é¡Œï¼š{question}
    
    å°ˆæ¥­æ¥­å‹™å“¡å›è¦†ï¼š
    """,
    input_variables=["context", "question"]
)

# å»ºç«‹æª¢ç´¢å•ç­”éˆ
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": qa_prompt}
)

# ==========================================
# 3. ä»‹é¢åŠŸèƒ½å¯¦ä½œ
# ==========================================

tab1, tab2 = st.tabs(["ğŸ’¬ ç·šä¸Šä¿éšªè«®è©¢", "ğŸ“‹ æ™ºèƒ½ä¿éšªæ¨è–¦"])

# --- åŠŸèƒ½ä¸€ï¼šChatbot ---
with tab1:
    st.subheader("æœ‰ä»€éº¼ä¿éšªå•é¡Œæˆ‘å¯ä»¥å¹«æ‚¨å—ï¼Ÿ")
    
    # åˆå§‹åŒ–èŠå¤©ç´€éŒ„
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # é¡¯ç¤ºæ­·å²è¨Šæ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # è™•ç†ä½¿ç”¨è€…è¼¸å…¥
    if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ (ä¾‹å¦‚ï¼šæ„å¤–éšªé©ç”¨æ–¼ä»€éº¼å ´æ™¯ï¼Ÿ)"):
        # 1. é¡¯ç¤ºä½¿ç”¨è€…å•é¡Œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # 2. ç”Ÿæˆå›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨æŸ¥é–±ä¿éšªæ¢æ¬¾..."):
                try:
                    # é€²è¡Œ RAG æª¢ç´¢èˆ‡ç”Ÿæˆ
                    response = qa_chain.invoke({"query": prompt})
                    result = response["result"]
                    
                    st.markdown(result)
                    st.session_state.messages.append({"role": "assistant", "content": result})
                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ï¼š{e}")

# --- åŠŸèƒ½äºŒï¼šä¿éšªæ¨è–¦ ---
with tab2:
    st.subheader("ç‚ºæ‚¨é‡èº«æ‰“é€ çš„ä¿éšªè¦åŠƒ")
    st.markdown("è«‹å¡«å¯«ä»¥ä¸‹è³‡è¨Šï¼ŒAI å°‡æ ¹æ“šæ‚¨çš„èƒŒæ™¯æ¨è–¦é©åˆçš„å•†å“ã€‚")

    # ä½¿ç”¨ container ä¾†åŒ…è£è¡¨å–®ï¼Œé¿å… st.form é™åˆ¶äº’å‹•æ€§
    with st.container(border=True):
        col1, col2 = st.columns(2)
        with col1:
            gender = st.selectbox("æ€§åˆ¥", ["ç”·", "å¥³"])
            age = st.number_input("å¹´é½¡", min_value=0, max_value=100, value=30)
            job = st.text_input("è·æ¥­", "ä¸€èˆ¬å…§å‹¤")
        with col2:
            salary = st.selectbox("å¹´æ”¶å…¥ç¯„åœ", ["50è¬ä»¥ä¸‹", "50-100è¬", "100-200è¬", "200è¬ä»¥ä¸Š"])
            budget = st.text_input("é ç®— (æœˆç¹³/å¹´ç¹³)", "æœˆç¹³ 3000 å…ƒ")
        
        # ä¿éšªé¡å‹é¸æ“‡
        ins_type = st.selectbox(
            "æ‚¨æ„Ÿèˆˆè¶£çš„ä¿éšªé¡å‹", 
            ["é†«ç™‚éšª", "æ„å¤–éšª", "å„²è“„éšª/æŠ•è³‡å‹", "æ—…éŠå¹³å®‰éšª", "é•·ç…§éšª", "å£½éšª"]
        )
        
        # å‹•æ…‹é¡¯ç¤ºï¼šå¦‚æœæ˜¯æ—…éŠéšªï¼Œå¤šé¡¯ç¤ºå…©å€‹æ¬„ä½
        travel_details = ""
        if ins_type == "æ—…éŠå¹³å®‰éšª":
            st.info("âœˆï¸ åµæ¸¬åˆ°æ—…éŠéœ€æ±‚ï¼Œè«‹è£œå……ç´°ç¯€ï¼š")
            c1, c2 = st.columns(2)
            with c1:
                dest = st.text_input("æ—…éŠåœ‹å®¶", "æ—¥æœ¬")
            with c2:
                days = st.number_input("æ—…éŠå¤©æ•¸", min_value=1, value=5)
            travel_details = f"ï¼Œæ—…éŠç›®çš„åœ°ç‚º{dest}ï¼Œé è¨ˆæ—…éŠ{days}å¤©"

        if st.button("ğŸš€ é–‹å§‹åˆ†æä¸¦æ¨è–¦", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†ææ‚¨çš„éœ€æ±‚ä¸¦æ¯”å°è³‡æ–™åº«..."):
                # çµ„åˆä½¿ç”¨è€…ç•«åƒ Prompt
                user_profile_query = f"""
                ä½¿ç”¨è€…åŸºæœ¬è³‡æ–™ï¼š
                - æ€§åˆ¥ï¼š{gender}
                - å¹´é½¡ï¼š{age}
                - è·æ¥­ï¼š{job}
                - å¹´æ”¶å…¥ï¼š{salary}
                - é ç®—ï¼š{budget}
                - ä¸»è¦éœ€æ±‚ï¼š{ins_type}{travel_details}
                
                ä»»å‹™ï¼š
                è«‹æ ¹æ“šä¸Šè¿°ä½¿ç”¨è€…æ¢ä»¶ï¼Œå¾è³‡æ–™åº«ä¸­æœå°‹æœ€é©åˆçš„ã€{ins_type}ã€‘å•†å“ã€‚
                è«‹åˆ—å‡ºæ¨è–¦çš„å•†å“åç¨±ï¼Œä¸¦è©³ç´°èªªæ˜æ¨è–¦åŸå› ï¼ˆä¾‹å¦‚è©²å•†å“æœ‰ä»€éº¼ç‰¹è‰²é©åˆé€™ä½ä½¿ç”¨è€…ï¼‰ã€‚
                è‹¥è³‡æ–™åº«ä¸­æ²’æœ‰å®Œå…¨åŒ¹é…çš„å•†å“ï¼Œè«‹æ¨è–¦æœ€æ¥è¿‘çš„é€šç”¨æ–¹æ¡ˆã€‚
                """
                
                try:
                    # é€™è£¡ç›´æ¥å¾©ç”¨ qa_chainï¼Œå› ç‚ºå®ƒå·²ç¶“åŒ…å«äº† "åªæ ¹æ“šè³‡æ–™åº«å›ç­”" çš„é™åˆ¶
                    # é€™æ¨£å¯ä»¥ç¢ºä¿æ¨è–¦çš„å•†å“ä¸€å®šæ˜¯è³‡æ–™åº«è£¡æœ‰çš„
                    response = qa_chain.invoke({"query": user_profile_query})
                    
                    st.success("åˆ†æå®Œæˆï¼ä»¥ä¸‹æ˜¯çµ¦æ‚¨çš„å°ˆæ¥­å»ºè­°ï¼š")
                    st.markdown("### ğŸ“‹ æ¨è–¦å ±å‘Š")
                    st.markdown(response["result"])
                except Exception as e:
                    st.error(f"åˆ†æå¤±æ•—ï¼š{e}")